# 01 Source all my functions ####
source("04_myFxnsThisProject.r")
# 02 Ensure all pkgs in this scripts are installed ####
pkgs <-
c(
"openxlsx")
activatePkgs(pkgs)
# 03 Backup former scraped data ####
sourceScriptFromFolder("s01_backup.r")
# 05 Getting exchange rate data for fiat pairs ####
sourceScriptFromFolder("s05_fiatRates.r")
# 08 Scraping data for Handelsbanken ISK ####
sourceScriptFromFolder("s08_hisk.r")
fonds <- c(
"Handelsbanken Hälsovård Tema SEK",
"Handelsbanken Hållbar Energi",
"Handelsbanken Euro Obligation"
)
hisk <- data.frame(
fonds,
price = c(rep(NA, length(fonds)))
)
urlPrefix <- "https://www.morningstar.se/se/funds/snapshot/snapshot.aspx?id="
hiskIds <-
c(
"F0GBR04F38",
"F00000UI2B",
"F00000UF2C"
)
hiskSitesToScrape <-
paste0(urlPrefix, hiskIds)
hisk
hisk %<>%
scrapeMultiple(hiskSitesToScrape, scrapeMorningstarDotSe)
url
url <- hisk[1, 1]
url
url <- hiskSitesToScrape[1]
url %>%
xml2::read_html(.)
url %>%
xml2::read_html(.) %>%
rvest::html_nodes("#overviewQuickstatsDiv tr:nth-child(2) .text")
url %>%
xml2::read_html(.) %>%
rvest::html_nodes("#overviewQuickstatsDiv tr:nth-child(2) .text") %>%
rvest::html_text(.)
url %>%
xml2::read_html(.) %>%
rvest::html_nodes("#overviewQuickstatsDiv tr:nth-child(2) .text") %>%
rvest::html_text(.) %>%
gsub("SEK|EUR|USD|\\s", "", .) %>%
gsub(",", ".", .) %>%
as.numeric()
sitesToScrape <- hiskSitesToScrape
i <- 1
tries <- 1
cat(paste0(
i,
" of ",
length(sitesToScrape),
" pairs: try ",
tries,
".\n\n"
))
scraperFunction <- scrapeMorningstarDotSe()
scraperFunction <- scrapeMorningstarDotSe
testit::has_error(
scraperFunction(sitesToScrape[i])
)
df <- hisk
df
df[["price"]][i]
scraperFunction(sitesToScrape[i])
scrapeMultiple(hisk, hiskSitesToScrape, scrapeMorningstarDotSe)
!exists("rd", envir = .GlobalEnv)
stopRd()
exists("rd", envir = .GlobalEnv)
gc()
# Loop to attempt to close ports in use by Selenium.
# It times out after timeoutLength in seconds.
resourceOccupied <- T
timeoutLength <- 10
timeoutTime <- Sys.time() + timeoutLength
scrapeMultiple <- function(df, sitesToScrape, scraperFunction) {
for (i in seq_along(sitesToScrape)) {
tries <- 1
while (tries <= 10) {
cat(paste0(
i,
" of ",
length(sitesToScrape),
" pairs: try ",
tries,
".\n\n"
))
if (testit::has_error(
scraperFunction(sitesToScrape[i])
)) {
Sys.sleep(20)
tries <- tries + 1
}
else {
df[["price"]][i] <-
scraperFunction(sitesToScrape[i])
tries <- 11
}
}
rm(tries)
}
# if (!exists("rd", envir = .GlobalEnv)) {
# stopRd()
# }
return(df)
}
scrapeMultiple(hisk, hiskSitesToScrape, scrapeMorningstarDotSe)
# 01 Source all my functions ####
source("04_myFxnsThisProject.r")
# 02 Ensure all pkgs in this scripts are installed ####
pkgs <-
c(
"openxlsx")
activatePkgs(pkgs)
# 03 Backup former scraped data ####
sourceScriptFromFolder("s01_backup.r")
# 04 Prioritize which cryptocurrencies to evaluate and trade ####
# Stopped holding investments in cryptos so I stopped scraping
# Coinmarketcap. Also, the use of the reticulate package seems
# to be failing.
# sourceScriptFromFolder("s02_ccPrioritizer.r")
# 05 Getting exchange rate data for fiat pairs ####
sourceScriptFromFolder("s05_fiatRates.r")
# 06 Scraping data from Kraken ####
# Stopped holding investments in cryptos so I stopped scraping
# Kraken.
# sourceScriptFromFolder("s06_kraken.r")
# 07 Scraping data for Robinhood ####
# Stopped scraping these since stopped investing in Robinhood
# sourceScriptFromFolder("s07_robinhood.r")
# 08 Scraping data for Handelsbanken ISK ####
sourceScriptFromFolder("s08_hisk.r")
View(hisk)
# 09 Scraping data for Handelsbanken Pension ####
sourceScriptFromFolder("s09_hpension.r")
# 10 Scraping data for SPP Pension ####
sourceScriptFromFolder("s10_spppension.r")
# 11 Scraping data for Premiepension ####
# Stopped scraping these since they stopped listing prices on their
# site and I have not found a better alternative site yet.
sourceScriptFromFolder("s11_premiepension.r")
# 12 Scraping data for Länsförsäkringar ####
sourceScriptFromFolder("s12_lansforsakringar.r")
# 13 Final save ####
openxlsx::saveWorkbook(myWb, myXlsx, overwrite = T)
# 14 Final QC test to see if all data scraped ####
allAssetsDf %<>% .[, c("Source", "fonds", "price")]
if (allAssetsDf[["price"]] %>% is.na %>% any) {
print("OBS! Not all data scraped! Observe:")
allAssetsDf
} else {
print("All data apparently scraped. Nice job!")
}
reticulate::source_python("05_scripts/s03_cmcScraper.py")
reticulate::source_python("05_scripts/s03_cmcScraper.py")
reticulate::source_python("05_scripts/s03_cmcScraper.py")
